msgid ""
msgstr ""
"Project-Id-Version: qiskit-docs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-11-28 18:30+0000\n"
"PO-Revision-Date: 2023-02-06 05:32\n"
"Last-Translator: \n"
"Language-Team: Japanese\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Crowdin-Project: qiskit-docs\n"
"X-Crowdin-Project-ID: 369271\n"
"X-Crowdin-Language: ja\n"
"X-Crowdin-File: /master/machine-learning/docs/locale/en/LC_MESSAGES/tutorials/01_neural_networks.po\n"
"X-Crowdin-File-ID: 9628\n"
"Language: ja_JP\n"

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "This page was generated from `docs/tutorials/01_neural_networks.ipynb`__."
msgstr "このページは `docs/tutorials/01_neural_networks.ipynb`__ から生成されました。"

#: ../../tutorials/01_neural_networks.ipynb:9
msgid "Quantum Neural Networks"
msgstr "量子ニューラル・ネットワーク"

#: ../../tutorials/01_neural_networks.ipynb:11
msgid "This notebook demonstrates the different generic quantum neural network (QNN) implementations provided in Qiskit Machine Learning. The networks are meant as application-agnostic computational units that can be used for many different use cases. Depending on the application, a particular type of network might be more or less suitable and might require to be set up in a particular way. The following different available neural networks will now be discussed in more detail:"
msgstr "このノートブックでは、 Qiskit 機械学習で提供される、さまざまな汎用的な量子ニューラル・ネットワーク (QNN) の実装を紹介します。 このネットワークは、アプリケーションに依存しない計算ユニットとして、様々なユースケースに使用することができます。アプリケーションによっては、特定のタイプのネットワークが適していたり、適していなかったり、特定の方法でセットアップする必要があったりします。ここでは、次のような種類のニューラルネットワークについて、詳しく説明します。"

#: ../../tutorials/01_neural_networks.ipynb:13
msgid "``NeuralNetwork``: The interface for neural networks. This is an abstract class."
msgstr "``NeuralNetwork``: ニューラルネットワークのインターフェイス。これは抽象クラスです。"

#: ../../tutorials/01_neural_networks.ipynb:14
msgid "``EstimatorQNN``: A network based on the evaluation of quantum mechanical observables."
msgstr "``EstimatorQNN``: 量子力学的観測量の評価に基づくネットワーク。"

#: ../../tutorials/01_neural_networks.ipynb:15
msgid "``SamplerQNN``: A network based on the samples resulting from measuring a quantum circuit."
msgstr "``SamplerQNN``: 量子回路を測定することによって得られたサンプルに基づいたネットワーク。"

#: ../../tutorials/01_neural_networks.ipynb:17
msgid "Each implementation, ``EstimatorQNN`` and ``SamplerQNN``, takes in an optional instance of the corresponding Qiskit primitive, namely ``BaseEstimator`` and ``BaseSampler``. The latter two define two interfaces of the primitives. Qiskit provides the reference implementation as well as a backend-based implementation of the primitives. The primitives is a frontend to either a simulator or a real quantum hardware. By default, if no instance is passed to a network, an instance of the Qiskit reference primitive is created automatically by the network. For more information about primitives please refer to `Qiskit primitives <https://qiskit.org/documentation/apidoc/primitives.html>`__."
msgstr "``EstimatorQNN``と ``SamplerQNN``の各実装は、対応するQiskit primitive、すなわち``BaseEstimator`` と``BaseSampler``のインスタンスをオプションとして取り込みます。後者の2つはprimitiveの2つのインターフェイスを定義しています。Qiskitはprimitiveのリファレンス実装と、バックエンドベースの実装を提供します。Primitiveはシミュレータや実量子ハードウェアのフロントエンドとなります。デフォルトでは、ネットワークにインスタンスが渡されない場合、Qiskit reference primitiveのインスタンスがネットワークによって自動的に作成されます。Primitiveの詳細については、`Qiskit primitives <https://qiskit.org/documentation/apidoc/primitives.html>`__ を参照してください。"

#: ../../tutorials/01_neural_networks.ipynb:45
msgid "1. ``NeuralNetwork``"
msgstr "1. ``NeuralNetwork``"

#: ../../tutorials/01_neural_networks.ipynb:47
msgid "The ``NeuralNetwork`` represents the interface for all neural networks available in Qiskit Machine Learning. It exposes a forward and a backward pass taking the data samples and trainable weights as input. A ``NeuralNetwork`` does not contain any training capabilities, these are pushed to the actual algorithms / applications. Thus, a ``NeuralNetwork`` also does not store the values for trainable weights. In the following, different implementations of this interface are introduced."
msgstr "``NeuralNetwork`` は、Qiskit MachineLearningで利用可能なすべてのニューラルネットワークのインターフェースを表します。データサンプルとトレーニング可能な重みを入力として取得する順伝播パスと逆伝搬パスを公開します。 ``NeuralNetwork`` にはトレーニング機能は含まれていません。これらは、実際のアルゴリズム/アプリケーションにプッシュされます。したがって、 ``NeuralNetwork`` は、トレーニング可能な重みの値も格納しません。以下では、このインターフェースのさまざまな実装を紹介します。"

#: ../../tutorials/01_neural_networks.ipynb:49
msgid "Suppose a ``NeuralNetwork`` called ``nn``. Then, the ``nn.forward(input, weights)`` pass takes both flat inputs for the data and weights of size ``nn.num_inputs`` and ``nn.num_weights``, respectively. ``NeuralNetwork`` supports batching of inputs and returns batches of output of the corresponding shape."
msgstr "``nn`` という ``NeuralNetwork`` を想定します。次に、 ``nn.forward(input, weights)`` パスは、データのフラット入力と、サイズ　``nn.num_inputs`` および ``nn.num_weights`` の重みをそれぞれ受け取ります。 ``NeuralNetwork`` は入力のバッチ処理をサポートし、対応する形状の出力のバッチを返します。"

#: ../../tutorials/01_neural_networks.ipynb:61
msgid "2. ``EstimatorQNN``"
msgstr "2. ``EstimatorQNN``"

#: ../../tutorials/01_neural_networks.ipynb:63
msgid "The ``EstimatorQNN`` takes in a parametrized quantum circuit with the combined network’s feature map (input parameters) and ansatz (weight parameters), as well as an optional quantum mechanical observable, and outputs expectation value computations for the forward pass. The quantum circuit parameters can be used to load classical data as well as represent trainable weights. The ``EstimatorQNN`` also allows lists of observables to construct more complex QNNs."
msgstr "``EstimatorQNN``は、ネットワークの特徴量マップ（入力パラメータ）とansatz（重みパラメータ）、およびオプションの量子力学的観測量をパラメーター化した量子回路を取り込み、フォワードパスに対する期待値計算を出力します。量子回路のパラメーターは、学習可能な重みを表すだけでなく、古典的なデータをロードするために使用することができます。また、``EstimatorQNN`` では、より複雑なQNNを構築するために観測値のリストを使用することができます。"

#: ../../tutorials/01_neural_networks.ipynb:109
msgid "We create an observable manually. If it is set, then The default observable :math:`Z^{\\otimes n}`, where :math:`n` is the number of qubits, is created automatically."
msgstr "手動で 観測量を作成します。もし、設定されていれば、デフォルトの 観測量 :math:`Z^{\\otimes n}` 、ここでの :math:`n` は量子ビットの数、は自動的に作成されます。"

#: ../../tutorials/01_neural_networks.ipynb:132
msgid "Construct EstimatorQNN with the observable, input parameters, and weight parameters. We don’t set the ``estimator`` parameter, the network will create an instance of the reference ``Estimator`` primitive for us."
msgstr "観測量、入力パラメータ、weightパラメーターを指定してEstimatorQNNを構築します。 ``estimator`` パラメーターは設定せず、ネットワークが参照用の ``Estimator`` primitiveのインスタンスを生成してくれます。"

#: ../../tutorials/01_neural_networks.ipynb:323
msgid "Combining multiple observables in a list allows to create more complex QNNs."
msgstr "リストで複数の観測量（オブザーバブル）を組み合わせることで、より複雑なQNNを作ることができます。"

#: ../../tutorials/01_neural_networks.ipynb:430
msgid "4. ``SamplerQNN``"
msgstr "4. ``SamplerQNN``"

#: ../../tutorials/01_neural_networks.ipynb:432
msgid "The ``SamplerQNN`` is based on a (parametrized) ``QuantumCircuit``. This can take input as well as weight parameters and produces samples from the measurement. The samples are interpreted as probabilities of measuring the integer index corresponding to a bitstring. Gradients can be estimated efficiently and the ``SamplerQNN`` provides a backward pass as well."
msgstr "``SamplerQNN`` は、（パラメーター化された） ``QuantumCircuit`` をベースにしています。これは、重みパラメーターだけでなく入力も受け取ることができ、測定値からサンプルを生成します。このサンプルは，ビット列に対応する整数のインデックスを計測する確率として解釈されます。勾配は効率的に推定することができ、 ``SamplerQNN`` はバックワードパスも提供します。"

#: ../../tutorials/01_neural_networks.ipynb:434
msgid "Further, the ``SamplerQNN`` allows to specify an ``interpret`` function to post-process the samples. This is expected to take a measured integer (from a bitstring) and map it to a new index, i.e. non-negative integer. In this case, the output shape needs to be provided and the probabilities are aggregated accordingly."
msgstr "さらに、 ``SamplerQNN`` では、サンプルを後処理するための ``interpret`` 関数を指定することができます。これは、（ビット列から）測定された整数を受け取り、それを新しいインデックス、すなわち非負の整数にマッピングすることが期待されます。この場合、出力の形を提供する必要があり、それに応じて確率が調整されます。"

#: ../../tutorials/01_neural_networks.ipynb:436
msgid "If no ``interpret`` function is used, the dimension of the probability vector scales exponentially with the number of qubits. In case of an ``interpret`` function it depends on the expected outcome. If, for instance, an index is mapped to the parity of the corresponding bitstring, i.e., to 0 or 1, a dense output makes sense and the result will be a probability vector of length 2."
msgstr "``interpret`` 関数を使用しない場合、確率ベクトルの次元は量子ビット数に応じて指数関数的に増加します。 ``interpret`` 関数を使用する場合は、期待される結果に依存します。例えば、インデックスが対応するビット列のパリティにマッピングされる場合、つまり0または1にマッピングされる場合、密な出力が意味を持ち、結果は長さ2の確率ベクトルになります。"

#: ../../tutorials/01_neural_networks.ipynb:478
msgid "As in the previous example, we don’t set the ``sampler`` parameter, the network will create an instance of the reference ``Sampler`` primitive for us."
msgstr "前の例と同様に、``sampler`` パラメーターを設定しないと、ネットワークが参照用の ``Sampler`` primitiveのインスタンスを生成してくれます。"

